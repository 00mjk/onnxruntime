<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONNX Runtime: ONNX Runtime</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ONNX Runtime
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">ONNX Runtime </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><div class="image">
<img src="docs/MSFT-Onnx-Runtime-11282019-Logo.png" width="50%"/>
</div>
<p><a href="https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=1"></a></p>
<h1>Introduction</h1>
<p>ONNX Runtime is an open-source scoring engine for Open Neural Network Exchange (ONNX) models.</p>
<p>ONNX is an open format for machine learning (ML) models that is supported by various ML and DNN frameworks and tools. This format makes it easier to interoperate between frameworks and to maximize the reach of your hardware optimization investments. Learn more about ONNX on <a href="https://onnx.ai">https://onnx.ai</a> or view the <a href="https://github.com/onnx/onnx">Github Repo</a>.</p>
<h1>Why use ONNX Runtime</h1>
<p>ONNX Runtime is an open architecture that is continually evolving to adapt to and address the newest developments and challenges in AI and Deep Learning. We will keep ONNX Runtime up to date with the ONNX standard, supporting all ONNX releases with future compatibliity while maintaining backwards compatibility with prior releases.</p>
<p>ONNX Runtime continuously strives to provide top performance for a broad and growing number of usage scenarios in Machine Learning. Our investments focus on these 3 core areas:</p><ol type="1">
<li>Run any ONNX model</li>
<li>High performance</li>
<li>Cross platform</li>
</ol>
<h2>Run any ONNX model</h2>
<h3>Alignment with ONNX Releases</h3>
<p>ONNX Runtime provides comprehensive support of the ONNX spec and can be used to run all models based on ONNX v1.2.1 and higher. See ONNX version release details <a href="https://github.com/onnx/onnx/releases">here</a>.</p>
<p>As of November 2018, ONNX Runtime supports the latest released version of ONNX (1.3). Once 1.4 is released, ONNX Runtime will align with the updated spec, adding support for new operators and other capabilities.</p>
<h3>Traditional ML support</h3>
<p>ONNX Runtime fully supports the ONNX-ML profile of the ONNX spec for traditional ML scenarios.</p>
<h2>High Performance</h2>
<p>You can use ONNX Runtime with both CPU and GPU hardware. You can also plug in additional execution providers to ONNX Runtime. With many graph optimizations and various accelerators, ONNX Runtime can often provide lower latency and higher efficiency compared to other runtimes. This provides smoother end-to-end customer experiences and lower costs from improved machine utilization.</p>
<p>Currently ONNX Runtime supports CUDA and MKL-DNN (with option to build with MKL) for computation acceleration. To add an execution provider, please refer to this page.</p>
<p>We are continuously working to integrate new execution providers to provide improvements in latency and efficiency. We have ongoing collaborations to integrate the following with ONNX Runtime:</p><ul>
<li>Intel MKL-DNN and nGraph</li>
<li>NVIDIA TensorRT</li>
</ul>
<h2>Cross Platform</h2>
<p>ONNX Runtime offers:</p><ul>
<li>APIs for Python, C#, and C (experimental)</li>
<li>Available for Linux, Windows, and Macâ€¯</li>
</ul>
<p>See API documentation and package installation instructions <a href="#Installation">below</a>.</p>
<p>Looking ahead: To broaden the reach of the runtime, we will continue investments to make ONNX Runtime available and compatible with more platforms. These include but are not limited to:</p><ul>
<li>C# for Linux, Mac</li>
<li>C# supporting GPU</li>
<li>C packages</li>
<li>ARM</li>
</ul>
<h1>Getting Started</h1>
<p>If you need a model: <br />
* Check out the <a href="https://github.com/onnx/models">ONNX Model Zoo</a> for ready-to-use pre-trained models.</p><ul>
<li>To get an ONNX model by exporting from various frameworks, see <a href="https://github.com/onnx/tutorials">ONNX Tutorials</a>.</li>
</ul>
<p>If you already have an ONNX model, just <a href="#Installation">install the runtime</a> for your machine to try it out. One easy way to deploy the model on the cloud is by using <a href="https://azure.microsoft.com/en-us/services/machine-learning-service">Azure Machine Learning</a>. See detailed instructions <a href="https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-build-deploy-onnx">here</a>.</p>
<h1>Installation</h1>
<h2>APIs and Official Builds</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">API Documentation  </th><th class="markdownTableHeadNone" colspan="2">CPU package   </th></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><a href="https://docs.microsoft.com/en-us/python/api/overview/azure/onnx/intro?view=azure-onnx-py">Python</a>  </td><td class="markdownTableBodyNone"><a href="https://pypi.org/project/onnxruntime/">Windows</a><br />
<a href="https://pypi.org/project/onnxruntime/">Linux</a><br />
<a href="https://pypi.org/project/onnxruntime/">Mac</a>  </td><td class="markdownTableBodyNone"><a href="https://pypi.org/project/onnxruntime-gpu">Windows</a><br />
<a href="https://pypi.org/project/onnxruntime-gpu/">Linux</a>   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone">C#  </td><td class="markdownTableBodyNone"><a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime/">Windows</a><br />
Linux - Coming Soon<br />
Mac - Coming Soon  </td><td class="markdownTableBodyNone">Coming Soon   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowOdd">
<td class="markdownTableBodyNone">C (experimental)  </td><td class="markdownTableBodyNone">Coming Soon  </td><td class="markdownTableBodyNone">Coming Soon   </td></tr>
<tr class="markdownTableBody" class="markdownTableRowEven">
<td class="markdownTableBodyNone"><a href="onnxruntime/core/session/inference_session.h">C++</a>  </td><td class="markdownTableBodyNone">TBD  </td><td class="markdownTableBodyNone">TBD   </td></tr>
</table>
<h2>Build Details</h2>
<p>For details on the build configurations and information on how to create a build, see <a class="el" href="BUILD_8md.html">Build ONNX Runtime</a>.</p>
<h2>Versioning</h2>
<p>See more details on API and ABI Versioning and ONNX Compatibility in Versioning.</p>
<h1>Design and Key Features</h1>
<p>For an overview of the high level architecture and key decisions in the technical design of ONNX Runtime, see Engineering Design.</p>
<p>ONNX Runtime is built with an extensible design that makes it versatile to support a wide array of models with high performance.</p>
<ul>
<li>Add a custom operator/kernel</li>
<li>Add an execution provider</li>
<li><a href="include/onnxruntime/core/graph/graph_transformer.h">Add a new graph transform</a></li>
<li><a href="include/onnxruntime/core/graph/rewrite_rule.h">Add a new rewrite rule</a></li>
</ul>
<h1>Contribute</h1>
<p>We welcome your contributions! Please see the <a class="el" href="CONTRIBUTING_8md.html">contribution guidelines</a>.</p>
<h2>Feedback</h2>
<p>For any feedback or to report a bug, please file a <a href="https://github.com/Microsoft/onnxruntime/issues">GitHub Issue</a>.</p>
<h2>Code of Conduct</h2>
<p>This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/">Microsoft Open Source Code of Conduct</a>. For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/">Code of Conduct FAQ</a> or contact <a href="#" onclick="location.href='mai'+'lto:'+'ope'+'nc'+'ode'+'@m'+'icr'+'os'+'oft'+'.c'+'om'; return false;">opencode@microsoft.com</a> with any additional questions or comments.</p>
<h1>License</h1>
<p>[MIT License](LICENSE) </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
